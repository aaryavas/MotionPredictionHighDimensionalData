{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9617624,"sourceType":"datasetVersion","datasetId":5869547},{"sourceId":9791327,"sourceType":"datasetVersion","datasetId":5999729}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport logging\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification, Trainer, TrainingArguments\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nprint(\"Passed\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:09.264367Z","iopub.execute_input":"2024-11-13T15:49:09.264861Z","iopub.status.idle":"2024-11-13T15:49:09.273200Z","shell.execute_reply.started":"2024-11-13T15:49:09.264819Z","shell.execute_reply":"2024-11-13T15:49:09.271938Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Passed\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = \"cuda\" if cuda.is_available() else \"cpu\"\nprint(\"passed\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:10.795434Z","iopub.execute_input":"2024-11-13T15:49:10.796615Z","iopub.status.idle":"2024-11-13T15:49:10.804277Z","shell.execute_reply.started":"2024-11-13T15:49:10.796550Z","shell.execute_reply":"2024-11-13T15:49:10.802634Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"passed\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Start to interpret the data","metadata":{}},{"cell_type":"code","source":"#data extraction\n\ntrain = pd.read_csv(\"/kaggle/input/motion/motionStrike_TVcodes_data.tsv\", delimiter='\\t' )\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:12.336225Z","iopub.execute_input":"2024-11-13T15:49:12.336712Z","iopub.status.idle":"2024-11-13T15:49:12.402557Z","shell.execute_reply.started":"2024-11-13T15:49:12.336668Z","shell.execute_reply":"2024-11-13T15:49:12.401279Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(13803, 22)"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:14.375915Z","iopub.execute_input":"2024-11-13T15:49:14.376384Z","iopub.status.idle":"2024-11-13T15:49:14.408585Z","shell.execute_reply.started":"2024-11-13T15:49:14.376342Z","shell.execute_reply":"2024-11-13T15:49:14.406868Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   CaseReferenceNumber  MotionID CaseLocation CaseMajorCode  CaseMinorCode  \\\n0                  207      1751          FBT             V              1   \n1                 1472     10915          FBT             V              1   \n2                 1494     11050          NNI             V              1   \n3                  371      2708          LLI             T             90   \n4                 1422     10373          HHD             T              2   \n\n   CaseTrialListType  CaseMarkingCode  CaseDispositionJudgeJurisNo  \\\n0                  9             16.0                     416586.0   \n1                  9             16.0                          NaN   \n2                  9             16.0                          NaN   \n3                 -1              NaN                     418028.0   \n4                 -1              NaN                     422394.0   \n\n  CaseDispositionDocketLegendCode MotionResultCode  ... MotionJurisNumber  \\\n0                         JDGDACT               GR  ...          418027.0   \n1                           WDACT               DN  ...          416586.0   \n2                           WDACT               GR  ...          422392.0   \n3                             SJD               OR  ...          418028.0   \n4                              SJ               GR  ...           81181.0   \n\n  MotionDocumentPriorityCode  CaseAttorneyJuris  CaseAttorneyType  \\\n0                         30           418027.0                 J   \n1                         30           416586.0                 R   \n2                         30           422392.0                 J   \n3                         30           418028.0                 R   \n4                         30            81181.0                 R   \n\n   MotionTimeDuration MotionDocumentTypeName  SelfRepBeforeMotionFileCount  \\\n0                78.0       MOTION TO STRIKE                             1   \n1                22.0       MOTION TO STRIKE                             0   \n2               285.0       MOTION TO STRIKE                             0   \n3               120.0       MOTION TO STRIKE                             0   \n4               153.0       MOTION TO STRIKE                             0   \n\n  SelfRepBeforeMotionDecidedCount  SelfRepBeforeMotionFileBool  \\\n0                               1                         True   \n1                               0                        False   \n2                               0                        False   \n3                               0                        False   \n4                               0                        False   \n\n   SelfRepBeforeMotionDecidedBool  \n0                            True  \n1                           False  \n2                           False  \n3                           False  \n4                           False  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseReferenceNumber</th>\n      <th>MotionID</th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>CaseMinorCode</th>\n      <th>CaseTrialListType</th>\n      <th>CaseMarkingCode</th>\n      <th>CaseDispositionJudgeJurisNo</th>\n      <th>CaseDispositionDocketLegendCode</th>\n      <th>MotionResultCode</th>\n      <th>...</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionDocumentPriorityCode</th>\n      <th>CaseAttorneyJuris</th>\n      <th>CaseAttorneyType</th>\n      <th>MotionTimeDuration</th>\n      <th>MotionDocumentTypeName</th>\n      <th>SelfRepBeforeMotionFileCount</th>\n      <th>SelfRepBeforeMotionDecidedCount</th>\n      <th>SelfRepBeforeMotionFileBool</th>\n      <th>SelfRepBeforeMotionDecidedBool</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>207</td>\n      <td>1751</td>\n      <td>FBT</td>\n      <td>V</td>\n      <td>1</td>\n      <td>9</td>\n      <td>16.0</td>\n      <td>416586.0</td>\n      <td>JDGDACT</td>\n      <td>GR</td>\n      <td>...</td>\n      <td>418027.0</td>\n      <td>30</td>\n      <td>418027.0</td>\n      <td>J</td>\n      <td>78.0</td>\n      <td>MOTION TO STRIKE</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1472</td>\n      <td>10915</td>\n      <td>FBT</td>\n      <td>V</td>\n      <td>1</td>\n      <td>9</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>WDACT</td>\n      <td>DN</td>\n      <td>...</td>\n      <td>416586.0</td>\n      <td>30</td>\n      <td>416586.0</td>\n      <td>R</td>\n      <td>22.0</td>\n      <td>MOTION TO STRIKE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1494</td>\n      <td>11050</td>\n      <td>NNI</td>\n      <td>V</td>\n      <td>1</td>\n      <td>9</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>WDACT</td>\n      <td>GR</td>\n      <td>...</td>\n      <td>422392.0</td>\n      <td>30</td>\n      <td>422392.0</td>\n      <td>J</td>\n      <td>285.0</td>\n      <td>MOTION TO STRIKE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>371</td>\n      <td>2708</td>\n      <td>LLI</td>\n      <td>T</td>\n      <td>90</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>418028.0</td>\n      <td>SJD</td>\n      <td>OR</td>\n      <td>...</td>\n      <td>418028.0</td>\n      <td>30</td>\n      <td>418028.0</td>\n      <td>R</td>\n      <td>120.0</td>\n      <td>MOTION TO STRIKE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1422</td>\n      <td>10373</td>\n      <td>HHD</td>\n      <td>T</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>422394.0</td>\n      <td>SJ</td>\n      <td>GR</td>\n      <td>...</td>\n      <td>81181.0</td>\n      <td>30</td>\n      <td>81181.0</td>\n      <td>R</td>\n      <td>153.0</td>\n      <td>MOTION TO STRIKE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"feature engineering for attorney specialization ","metadata":{}},{"cell_type":"code","source":"#dirchlet multinomial distribution\nfrom scipy.stats import entropy\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sys\nimport math\nfrom multiprocessing import Pool\nimport random\n\n#create isolated dataset for attorny calc \nspecialtab = train[[\"CaseAttorneyJuris\", \"CaseMajorCode\"]]\nspecialtab.head()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:20.480424Z","iopub.execute_input":"2024-11-13T15:49:20.480865Z","iopub.status.idle":"2024-11-13T15:49:20.498628Z","shell.execute_reply.started":"2024-11-13T15:49:20.480825Z","shell.execute_reply":"2024-11-13T15:49:20.496933Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   CaseAttorneyJuris CaseMajorCode\n0           418027.0             V\n1           416586.0             V\n2           422392.0             V\n3           418028.0             T\n4            81181.0             T","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseAttorneyJuris</th>\n      <th>CaseMajorCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>418027.0</td>\n      <td>V</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>416586.0</td>\n      <td>V</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>422392.0</td>\n      <td>V</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>418028.0</td>\n      <td>T</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>81181.0</td>\n      <td>T</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndef calculate_attorney_specialization(specialtab):\n    # Make a copy of the input dataframe to avoid the warning\n    df = specialtab.copy()\n    \n    # Group by attorney and count case types\n    case_counts = pd.crosstab(df['CaseAttorneyJuris'], \n                             df['CaseMajorCode'])\n    \n    # Calculate entropy with Dirichlet smoothing for each attorney\n    attorney_entropy = {}\n    for attorney in case_counts.index:\n        counts = case_counts.loc[attorney]\n        \n        # Apply Dirichlet smoothing (adding 1 to each count)\n        smoothed_counts = counts + 1\n        # Calculate proportions\n        proportions = smoothed_counts / smoothed_counts.sum()\n        # Calculate entropy\n        attorney_entropy[attorney] = entropy(proportions, base=2)\n    \n    # Add entropy back to dataframe\n    df['AttorneySpecialization'] = df['CaseAttorneyJuris'].map(attorney_entropy)\n    \n    return df\nprint(\"function passed\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:23.636052Z","iopub.execute_input":"2024-11-13T15:49:23.636560Z","iopub.status.idle":"2024-11-13T15:49:23.646401Z","shell.execute_reply.started":"2024-11-13T15:49:23.636514Z","shell.execute_reply":"2024-11-13T15:49:23.645044Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"function passed\n","output_type":"stream"}]},{"cell_type":"markdown","source":"test the above code","metadata":{}},{"cell_type":"code","source":"# Use the function\nspecialentropy = calculate_attorney_specialization(specialtab)\n\n# Look at entropy scores\nprint(\"\\nEntropy scores:\")\nprint(specialentropy.groupby('CaseAttorneyJuris')['AttorneySpecialization'].head())\n\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:25.741946Z","iopub.execute_input":"2024-11-13T15:49:25.742438Z","iopub.status.idle":"2024-11-13T15:49:26.092536Z","shell.execute_reply.started":"2024-11-13T15:49:25.742394Z","shell.execute_reply":"2024-11-13T15:49:26.091312Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\nEntropy scores:\n0        0.999273\n1        0.992774\n2        0.999571\n3        0.902393\n4        0.977001\n           ...   \n13730    0.954434\n13752    0.985228\n13760    0.954434\n13768    0.985228\n13776    0.985228\nName: AttorneySpecialization, Length: 1276, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"#To see most specialized attorneys\nprint(\"\\nMost specialized attorneys (lowest entropy):\")\nprint(specialentropy.groupby('CaseAttorneyJuris')\n      .agg({'AttorneySpecialization': 'first', 'CaseMajorCode': lambda x: x.value_counts().to_dict()})\n      .sort_values('AttorneySpecialization')\n      .head())","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:28.362870Z","iopub.execute_input":"2024-11-13T15:49:28.364275Z","iopub.status.idle":"2024-11-13T15:49:28.492731Z","shell.execute_reply.started":"2024-11-13T15:49:28.364215Z","shell.execute_reply":"2024-11-13T15:49:28.491219Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\nMost specialized attorneys (lowest entropy):\n                   AttorneySpecialization      CaseMajorCode\nCaseAttorneyJuris                                           \n407897.0                         0.286397          {'T': 18}\n412189.0                         0.391244          {'T': 11}\n435703.0                         0.413817          {'T': 10}\n80808.0                          0.413817          {'T': 10}\n81240.0                          0.422001  {'T': 31, 'V': 2}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"New trained database:\n","metadata":{}},{"cell_type":"code","source":"specialentropy.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:31.275009Z","iopub.execute_input":"2024-11-13T15:49:31.275875Z","iopub.status.idle":"2024-11-13T15:49:31.291331Z","shell.execute_reply.started":"2024-11-13T15:49:31.275828Z","shell.execute_reply":"2024-11-13T15:49:31.289672Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   CaseAttorneyJuris CaseMajorCode  AttorneySpecialization\n0           418027.0             V                0.999273\n1           416586.0             V                0.992774\n2           422392.0             V                0.999571\n3           418028.0             T                0.902393\n4            81181.0             T                0.977001","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseAttorneyJuris</th>\n      <th>CaseMajorCode</th>\n      <th>AttorneySpecialization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>418027.0</td>\n      <td>V</td>\n      <td>0.999273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>416586.0</td>\n      <td>V</td>\n      <td>0.992774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>422392.0</td>\n      <td>V</td>\n      <td>0.999571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>418028.0</td>\n      <td>T</td>\n      <td>0.902393</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>81181.0</td>\n      <td>T</td>\n      <td>0.977001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"legal = train[[\"CaseLocation\",\"CaseMajorCode\",\"MotionJurisNumber\",\"MotionResultCode\"]]\nprint(\"passed\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:32.755488Z","iopub.execute_input":"2024-11-13T15:49:32.755935Z","iopub.status.idle":"2024-11-13T15:49:32.764312Z","shell.execute_reply.started":"2024-11-13T15:49:32.755863Z","shell.execute_reply":"2024-11-13T15:49:32.762945Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"passed\n","output_type":"stream"}]},{"cell_type":"code","source":"legal.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:35.336232Z","iopub.execute_input":"2024-11-13T15:49:35.336714Z","iopub.status.idle":"2024-11-13T15:49:35.353355Z","shell.execute_reply.started":"2024-11-13T15:49:35.336672Z","shell.execute_reply":"2024-11-13T15:49:35.352003Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"  CaseLocation CaseMajorCode  MotionJurisNumber MotionResultCode\n0          FBT             V           418027.0               GR\n1          FBT             V           416586.0               DN\n2          NNI             V           422392.0               GR\n3          LLI             T           418028.0               OR\n4          HHD             T            81181.0               GR","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionResultCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>418027.0</td>\n      <td>GR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>416586.0</td>\n      <td>DN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NNI</td>\n      <td>V</td>\n      <td>422392.0</td>\n      <td>GR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LLI</td>\n      <td>T</td>\n      <td>418028.0</td>\n      <td>OR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HHD</td>\n      <td>T</td>\n      <td>81181.0</td>\n      <td>GR</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"combine data sets together","metadata":{}},{"cell_type":"code","source":"# we need to add Attorney specialization to the legal data group for easier training in the future\nlegal = legal.assign(AttorneySpecialization=specialentropy[\"AttorneySpecialization\"])\nlegal.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:37.429121Z","iopub.execute_input":"2024-11-13T15:49:37.429610Z","iopub.status.idle":"2024-11-13T15:49:37.449281Z","shell.execute_reply.started":"2024-11-13T15:49:37.429569Z","shell.execute_reply":"2024-11-13T15:49:37.447489Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"  CaseLocation CaseMajorCode  MotionJurisNumber MotionResultCode  \\\n0          FBT             V           418027.0               GR   \n1          FBT             V           416586.0               DN   \n2          NNI             V           422392.0               GR   \n3          LLI             T           418028.0               OR   \n4          HHD             T            81181.0               GR   \n\n   AttorneySpecialization  \n0                0.999273  \n1                0.992774  \n2                0.999571  \n3                0.902393  \n4                0.977001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionResultCode</th>\n      <th>AttorneySpecialization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>418027.0</td>\n      <td>GR</td>\n      <td>0.999273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>416586.0</td>\n      <td>DN</td>\n      <td>0.992774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NNI</td>\n      <td>V</td>\n      <td>422392.0</td>\n      <td>GR</td>\n      <td>0.999571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LLI</td>\n      <td>T</td>\n      <td>418028.0</td>\n      <td>OR</td>\n      <td>0.902393</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HHD</td>\n      <td>T</td>\n      <td>81181.0</td>\n      <td>GR</td>\n      <td>0.977001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We need to split the data into two groups, one for training and one for testing, we are trying to use these data values to predict the outcome of MotionResultCode","metadata":{}},{"cell_type":"markdown","source":"We only want granted or denied motion codes so we need to filter everything but GR,DN,DS","metadata":{}},{"cell_type":"code","source":"filtered = legal[legal[\"MotionResultCode\"].isin([\"GR\",\"DN\"])]\nprint(\"passed\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:39.633497Z","iopub.execute_input":"2024-11-13T15:49:39.634009Z","iopub.status.idle":"2024-11-13T15:49:39.645169Z","shell.execute_reply.started":"2024-11-13T15:49:39.633961Z","shell.execute_reply":"2024-11-13T15:49:39.643729Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"passed\n","output_type":"stream"}]},{"cell_type":"code","source":"filtered.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:42.560816Z","iopub.execute_input":"2024-11-13T15:49:42.561451Z","iopub.status.idle":"2024-11-13T15:49:42.582368Z","shell.execute_reply.started":"2024-11-13T15:49:42.561396Z","shell.execute_reply":"2024-11-13T15:49:42.580834Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"  CaseLocation CaseMajorCode  MotionJurisNumber MotionResultCode  \\\n0          FBT             V           418027.0               GR   \n1          FBT             V           416586.0               DN   \n2          NNI             V           422392.0               GR   \n4          HHD             T            81181.0               GR   \n6          MMX             T           403965.0               DN   \n\n   AttorneySpecialization  \n0                0.999273  \n1                0.992774  \n2                0.999571  \n4                0.977001  \n6                0.976310  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionResultCode</th>\n      <th>AttorneySpecialization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>418027.0</td>\n      <td>GR</td>\n      <td>0.999273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>416586.0</td>\n      <td>DN</td>\n      <td>0.992774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NNI</td>\n      <td>V</td>\n      <td>422392.0</td>\n      <td>GR</td>\n      <td>0.999571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HHD</td>\n      <td>T</td>\n      <td>81181.0</td>\n      <td>GR</td>\n      <td>0.977001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MMX</td>\n      <td>T</td>\n      <td>403965.0</td>\n      <td>DN</td>\n      <td>0.976310</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"we need to create embedding and start to represent word variables as numbers for training","metadata":{}},{"cell_type":"code","source":"#apply one hot to MotionResultCode\n#make this a function later\none_hot = pd.get_dummies(filtered[\"MotionResultCode\"])\none_hot = one_hot.drop(\"DN\", axis = 1)\none_hot.rename(columns={\"GR\" : \"MotionResultCode\"}, inplace=True)\none_hot = one_hot.astype(int)\none_hot.head()\n\n#Motion Result Code == 1 means that Motion is GRANTED\n#Motion Result Code == 0 means that Motion is DENIED","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:44.962326Z","iopub.execute_input":"2024-11-13T15:49:44.962787Z","iopub.status.idle":"2024-11-13T15:49:44.983656Z","shell.execute_reply.started":"2024-11-13T15:49:44.962747Z","shell.execute_reply":"2024-11-13T15:49:44.982185Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   MotionResultCode\n0                 1\n1                 0\n2                 1\n4                 1\n6                 0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MotionResultCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#add one_hot back to the orginal data set filtered and remove current motionresultcode\nfiltered = filtered.assign(MotionResultCode=one_hot[\"MotionResultCode\"])\nfiltered","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:47.543436Z","iopub.execute_input":"2024-11-13T15:49:47.544734Z","iopub.status.idle":"2024-11-13T15:49:47.564662Z","shell.execute_reply.started":"2024-11-13T15:49:47.544680Z","shell.execute_reply":"2024-11-13T15:49:47.563286Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"      CaseLocation CaseMajorCode  MotionJurisNumber  MotionResultCode  \\\n0              FBT             V           418027.0                 1   \n1              FBT             V           416586.0                 0   \n2              NNI             V           422392.0                 1   \n4              HHD             T            81181.0                 1   \n6              MMX             T           403965.0                 0   \n...            ...           ...                ...               ...   \n13796          FBT             T           413629.0                 0   \n13797          NNH             V           421279.0                 0   \n13799          HHB             T           431662.0                 0   \n13800          TTD             T           436946.0                 1   \n13801          FBT             T           438581.0                 1   \n\n       AttorneySpecialization  \n0                    0.999273  \n1                    0.992774  \n2                    0.999571  \n4                    0.977001  \n6                    0.976310  \n...                       ...  \n13796                0.998296  \n13797                0.967387  \n13799                0.884115  \n13800                0.991076  \n13801                0.989588  \n\n[9192 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionResultCode</th>\n      <th>AttorneySpecialization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>418027.0</td>\n      <td>1</td>\n      <td>0.999273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FBT</td>\n      <td>V</td>\n      <td>416586.0</td>\n      <td>0</td>\n      <td>0.992774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NNI</td>\n      <td>V</td>\n      <td>422392.0</td>\n      <td>1</td>\n      <td>0.999571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HHD</td>\n      <td>T</td>\n      <td>81181.0</td>\n      <td>1</td>\n      <td>0.977001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MMX</td>\n      <td>T</td>\n      <td>403965.0</td>\n      <td>0</td>\n      <td>0.976310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13796</th>\n      <td>FBT</td>\n      <td>T</td>\n      <td>413629.0</td>\n      <td>0</td>\n      <td>0.998296</td>\n    </tr>\n    <tr>\n      <th>13797</th>\n      <td>NNH</td>\n      <td>V</td>\n      <td>421279.0</td>\n      <td>0</td>\n      <td>0.967387</td>\n    </tr>\n    <tr>\n      <th>13799</th>\n      <td>HHB</td>\n      <td>T</td>\n      <td>431662.0</td>\n      <td>0</td>\n      <td>0.884115</td>\n    </tr>\n    <tr>\n      <th>13800</th>\n      <td>TTD</td>\n      <td>T</td>\n      <td>436946.0</td>\n      <td>1</td>\n      <td>0.991076</td>\n    </tr>\n    <tr>\n      <th>13801</th>\n      <td>FBT</td>\n      <td>T</td>\n      <td>438581.0</td>\n      <td>1</td>\n      <td>0.989588</td>\n    </tr>\n  </tbody>\n</table>\n<p>9192 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Beta Bernouli for CaseMajorCode\n#Tort ==1 Vehicular == 0 \n#turn into function\nfiltered['CaseMajorCode'] = filtered['CaseMajorCode'].apply(lambda x: 1 if x == 'T' else 0)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:52.599698Z","iopub.execute_input":"2024-11-13T15:49:52.600169Z","iopub.status.idle":"2024-11-13T15:49:52.615024Z","shell.execute_reply.started":"2024-11-13T15:49:52.600126Z","shell.execute_reply":"2024-11-13T15:49:52.613480Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"filtered","metadata":{"execution":{"iopub.status.busy":"2024-11-13T15:49:57.428499Z","iopub.execute_input":"2024-11-13T15:49:57.429014Z","iopub.status.idle":"2024-11-13T15:49:57.447413Z","shell.execute_reply.started":"2024-11-13T15:49:57.428961Z","shell.execute_reply":"2024-11-13T15:49:57.445969Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"      CaseLocation  CaseMajorCode  MotionJurisNumber  MotionResultCode  \\\n0              FBT              0           418027.0                 1   \n1              FBT              0           416586.0                 0   \n2              NNI              0           422392.0                 1   \n4              HHD              1            81181.0                 1   \n6              MMX              1           403965.0                 0   \n...            ...            ...                ...               ...   \n13796          FBT              1           413629.0                 0   \n13797          NNH              0           421279.0                 0   \n13799          HHB              1           431662.0                 0   \n13800          TTD              1           436946.0                 1   \n13801          FBT              1           438581.0                 1   \n\n       AttorneySpecialization  \n0                    0.999273  \n1                    0.992774  \n2                    0.999571  \n4                    0.977001  \n6                    0.976310  \n...                       ...  \n13796                0.998296  \n13797                0.967387  \n13799                0.884115  \n13800                0.991076  \n13801                0.989588  \n\n[9192 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseLocation</th>\n      <th>CaseMajorCode</th>\n      <th>MotionJurisNumber</th>\n      <th>MotionResultCode</th>\n      <th>AttorneySpecialization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FBT</td>\n      <td>0</td>\n      <td>418027.0</td>\n      <td>1</td>\n      <td>0.999273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FBT</td>\n      <td>0</td>\n      <td>416586.0</td>\n      <td>0</td>\n      <td>0.992774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NNI</td>\n      <td>0</td>\n      <td>422392.0</td>\n      <td>1</td>\n      <td>0.999571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HHD</td>\n      <td>1</td>\n      <td>81181.0</td>\n      <td>1</td>\n      <td>0.977001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MMX</td>\n      <td>1</td>\n      <td>403965.0</td>\n      <td>0</td>\n      <td>0.976310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13796</th>\n      <td>FBT</td>\n      <td>1</td>\n      <td>413629.0</td>\n      <td>0</td>\n      <td>0.998296</td>\n    </tr>\n    <tr>\n      <th>13797</th>\n      <td>NNH</td>\n      <td>0</td>\n      <td>421279.0</td>\n      <td>0</td>\n      <td>0.967387</td>\n    </tr>\n    <tr>\n      <th>13799</th>\n      <td>HHB</td>\n      <td>1</td>\n      <td>431662.0</td>\n      <td>0</td>\n      <td>0.884115</td>\n    </tr>\n    <tr>\n      <th>13800</th>\n      <td>TTD</td>\n      <td>1</td>\n      <td>436946.0</td>\n      <td>1</td>\n      <td>0.991076</td>\n    </tr>\n    <tr>\n      <th>13801</th>\n      <td>FBT</td>\n      <td>1</td>\n      <td>438581.0</td>\n      <td>1</td>\n      <td>0.989588</td>\n    </tr>\n  </tbody>\n</table>\n<p>9192 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we need to apply tfidf to the complaint documents to remove lowly weighted words such as the and focus only on important words such as \n","metadata":{}},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Simple class to store term and its importance score\nclass TermScore:\n    def __init__(self, term, score):\n        self.term = term\n        self.score = score\n    \n    def __str__(self):\n        # Format like: word(0.123)\n        return f\"{self.term}({self.score:.3f})\"\n\ndef clean_text(text):\n    \"\"\"\n    Clean up text by removing special characters and converting to lowercase\n    \"\"\"\n    # Remove anything that's not a letter or space\n    cleaned = re.sub(r'[^a-zA-Z ]+', '', text)\n    return cleaned.lower().strip()\n\ndef clean_texts_in_dataframe(df, text_column='text'):\n    \"\"\"\n    Clean all texts in a DataFrame column\n    \"\"\"\n    if text_column not in df.columns:\n        print(f\"Error: '{text_column}' column not found!\")\n        return None\n        \n    # Make a copy so we don't change the original\n    df_copy = df.copy()\n    df_copy[text_column] = df_copy[text_column].apply(clean_text)\n    return df_copy\n\nclass TextProcessor:\n    \"\"\"\n    Main class to handle text processing using TF-IDF\n    \"\"\"\n    def __init__(self, max_features=None):\n        # Initialize the TF-IDF vectorizer\n        self.vectorizer = TfidfVectorizer(\n            max_features=max_features,\n            stop_words='english',               \n        \n        )\n        \n    def calculate_tfidf(self, documents):\n        # Convert documents to TF-IDF matrix\n        tfidf_matrix = self.vectorizer.fit_transform(documents)\n        \n        # Get the words (features) that correspond to the matrix columns\n        feature_names = self.vectorizer.get_feature_names_out()\n        \n        return {\n            'matrix': tfidf_matrix.todense(),\n            'words': feature_names\n        }\n    \n    def process_documents(self, documents, max_words=100, show_scores=True):\n        \"\"\"\n        Process documents and keep only the most important words based on TF-IDF\n        \"\"\"\n        # First clean the texts\n        cleaned_docs = [clean_text(doc) for doc in documents]\n        \n        # Calculate TF-IDF\n        result = self.calculate_tfidf(cleaned_docs)\n        matrix = result['matrix']\n        words = result['words']\n        \n        processed_documents = []\n        \n        # Go through each document\n        for doc_idx, doc_scores in enumerate(matrix):\n            # Create a dictionary of word:score pairs\n            word_scores = {}\n            for word_idx, score in enumerate(doc_scores.T):\n                word_scores[words[word_idx]] = float(score)\n            \n            # Sort words by score and keep top ones\n            sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n            top_words = dict(sorted_words[:max_words])\n            \n            # Process original document words\n            processed_words = []\n            for word in cleaned_docs[doc_idx].split():\n                if word in top_words:\n                    if show_scores:\n                        # Add the word with its score\n                        term = TermScore(word, top_words[word])\n                        processed_words.append(str(term))\n                    else:\n                        processed_words.append(word)\n            \n            processed_documents.append(' '.join(processed_words))\n        \n        return processed_documents\n    \n    def get_word_scores(self, result, doc_index, min_score=0.0):\n        \"\"\"\n        Get all words and their importance scores for a specific document\n        \"\"\"\n        doc_scores = result['matrix'][doc_index]\n        \n        # Create list of word-score pairs\n        word_scores = []\n        for word_idx, score in enumerate(doc_scores.T):\n            score_value = float(score)\n            if score_value >= min_score:\n                word_scores.append(\n                    TermScore(result['words'][word_idx], score_value)\n                )\n        \n        # Sort by score (highest first)\n        return sorted(word_scores, key=lambda x: x.score, reverse=True)\n\ndef process_file(input_file, output_file, text_column='text', max_words=100):\n    \"\"\"\n    Process text data from a file and save results\n    \"\"\"\n    try:\n        # Read the file (works with CSV or TSV)\n        if input_file.endswith('.tsv'):\n            df = pd.read_csv(input_file, sep='\\t')\n        else:\n            df = pd.read_csv(input_file)\n        \n        # Process the texts\n        processor = TextProcessor()\n        df = clean_texts_in_dataframe(df, text_column)\n        texts = df[text_column].tolist()\n        \n        # Get TF-IDF scores and process\n        processed_texts = processor.process_documents(texts, max_words)\n        \n        # Update and save\n        df[text_column] = processed_texts\n        df.to_csv(output_file, sep='\\t', index=False)\n        \n        return df\n        \n    except FileNotFoundError:\n        print(f\"Error: Couldn't find file: {input_file}\")\n        return None\n\n# Example usage / testing\nif __name__ == \"__main__\":\n    # Test with some example documents\n    test_docs = [\n        \"I enjoy reading about Machine Learning and Machine Learning is my PhD subject\",\n        \"I would enjoy a walk in the park\",\n        \"I was reading in the library\"\n    ]\n    \n    # Create test DataFrame\n    test_df = pd.DataFrame({\"text\": test_docs})\n    \n    # Create processor and process documents\n    processor = TextProcessor()\n    \n    # Clean the texts\n    cleaned_df = clean_texts_in_dataframe(test_df)\n    cleaned_texts = cleaned_df[\"text\"].tolist()\n    \n    # Process documents keeping top 5 words with scores\n    processed_texts = processor.process_documents(\n        cleaned_texts,\n        max_words=5,\n        show_scores=True\n    )\n    \n    # Show results\n    test_df[\"processed_text\"] = processed_texts\n    print(\"\\nProcessed Texts with Scores:\")\n    print(test_df[[\"text\", \"processed_text\"]])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:02:03.923002Z","iopub.execute_input":"2024-11-20T17:02:03.923435Z","iopub.status.idle":"2024-11-20T17:02:04.938184Z","shell.execute_reply.started":"2024-11-20T17:02:03.923400Z","shell.execute_reply":"2024-11-20T17:02:04.937136Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\nProcessed Texts with Scores:\n                                                text  \\\n0  I enjoy reading about Machine Learning and Mac...   \n1                   I would enjoy a walk in the park   \n2                       I was reading in the library   \n\n                                      processed_text  \n0  enjoy(0.228) machine(0.599) learning(0.599) ma...  \n1               enjoy(0.474) walk(0.623) park(0.623)  \n2                      reading(0.605) library(0.796)  \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/1118261806.py:80: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  word_scores[words[word_idx]] = float(score)\n","output_type":"stream"}]},{"cell_type":"code","source":"#open complaint documents\nfile_path = '/kaggle/input/complaint-docs/complaintDocs_BertForClass.txt'\ncomplaint_df = pd.read_csv(file_path, sep='\\t', names=['docid', 'text', 'MotionResultCode'])\ndocs_df = pd.DataFrame(complaint_df, columns=['text'])\n\n#process\nprocessor = TextProcessor()\n\n#clean \ncleaned_df = clean_texts_in_dataframe(docs_df)\ncleaned_texts = cleaned_df[\"text\"].tolist()\n\n#process and keep top 5 words\nprocessed_texts = processor.process_documents(\n        cleaned_texts,\n        max_words=5,\n        show_scores=True\n    )\n\n#results\ndocs_df[\"processed_text\"] = processed_texts\nprint(\"\\nProcessed Texts with Scores:\")\nprint(docs_df[[\"text\", \"processed_text\"]])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:02:10.282167Z","iopub.execute_input":"2024-11-20T17:02:10.282709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we need to import the complaint documents to run tfidf \nfile_path = '/kaggle/input/complaint-docs/complaintDocs_BertForClass.txt'\ncomplaint_df = pd.read_csv(file_path, sep='\\t', names=['docid', 'text', 'MotionResultCode'])\nprint(complaint_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T01:59:58.102343Z","iopub.execute_input":"2024-11-20T01:59:58.102761Z","iopub.status.idle":"2024-11-20T02:00:00.333995Z","shell.execute_reply.started":"2024-11-20T01:59:58.102724Z","shell.execute_reply":"2024-11-20T02:00:00.332642Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"        docid                                               text  \\\n0       docid                                               text   \n1          77  Return Date: April 19, 2005 Superior Court Luc...   \n2         453  RETURN DATE: MAY 10, 2005 SUPERIOR COURT MAURE...   \n3         579  RETURN DATE: MAY 3, 2005 SUPERIOR COURT VERNON...   \n4         669  1997 RETURN DATE: MAY 17, 2005 .. SUPERIOR COU...   \n...       ...                                                ...   \n8212  9989009  RETURN DATE: FEBRUARY 23, 2016 \" SUPERIOR COUR...   \n8213  9992499  RETURN DATE: FEBRUARY 16, 2016 : SUPERIOR COUR...   \n8214  9996383  RET: RV DATE: FEBRUARY.2.2016 SUPERIOR COUR JE...   \n8215  9999634  RETURN: FEBRUARY 23, 2016 SUPERIOR COURT LINDS...   \n8216  9999747  RETURN DATE: FEBRUARY 16, 2016 SUPERIOR COURT ...   \n\n      MotionResultCode  \n0     MotionResultCode  \n1                   OF  \n2                   GR  \n3                   OR  \n4                   OR  \n...                ...  \n8212                OR  \n8213                OR  \n8214                GR  \n8215                GR  \n8216                OR  \n\n[8217 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# we only want to apply these changes on column \"text\" so isolate column \n\n\nctemp_df = pd.DataFrame(complaint_df, columns=['text'])\nprint(ctemp_df)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:00:03.999367Z","iopub.execute_input":"2024-11-20T02:00:03.999738Z","iopub.status.idle":"2024-11-20T02:00:04.012277Z","shell.execute_reply.started":"2024-11-20T02:00:03.999707Z","shell.execute_reply":"2024-11-20T02:00:04.011131Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"                                                   text\n0                                                  text\n1     Return Date: April 19, 2005 Superior Court Luc...\n2     RETURN DATE: MAY 10, 2005 SUPERIOR COURT MAURE...\n3     RETURN DATE: MAY 3, 2005 SUPERIOR COURT VERNON...\n4     1997 RETURN DATE: MAY 17, 2005 .. SUPERIOR COU...\n...                                                 ...\n8212  RETURN DATE: FEBRUARY 23, 2016 \" SUPERIOR COUR...\n8213  RETURN DATE: FEBRUARY 16, 2016 : SUPERIOR COUR...\n8214  RET: RV DATE: FEBRUARY.2.2016 SUPERIOR COUR JE...\n8215  RETURN: FEBRUARY 23, 2016 SUPERIOR COURT LINDS...\n8216  RETURN DATE: FEBRUARY 16, 2016 SUPERIOR COURT ...\n\n[8217 rows x 1 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"ctemp_df = __normalizeDataset(ctemp_df)\n\n\nprint(ctemp_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:00:06.440031Z","iopub.execute_input":"2024-11-20T02:00:06.440827Z","iopub.status.idle":"2024-11-20T02:00:10.374898Z","shell.execute_reply.started":"2024-11-20T02:00:06.440781Z","shell.execute_reply":"2024-11-20T02:00:10.373728Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"                                                   text\n0                                                  text\n1     return date april   superior court lucille ame...\n2     return date may   superior court maureen lebla...\n3     return date may   superior court vernon skill ...\n4     return date may    superior court bryce ridley...\n...                                                 ...\n8212  return date february    superior court  nicole...\n8213  return date february    superior court kenya h...\n8214  ret rv date february superior cour jeffrey hay...\n8215  return february   superior court lindsay horny...\n8216  return date february   superior court ausrele ...\n\n[8217 rows x 1 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"t = ctemp_df[\"text\"].tolist()\ndocs_matrix, feature_names = tfIdf(t)\ntfidf_df = pd.DataFrame(docs_matrix, columns=feature_names)  # Each word (feature) becomes a column\nres = mapTfIdfToDocs(docs_matrix, feature_names, t, 5)\nctemp_df[\"text\"] = res\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:28:44.892511Z","iopub.execute_input":"2024-11-20T02:28:44.892919Z","iopub.status.idle":"2024-11-20T02:28:50.914574Z","shell.execute_reply.started":"2024-11-20T02:28:44.892885Z","shell.execute_reply":"2024-11-20T02:28:50.913431Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"                                                   text  \\\n0                                                  text   \n1     lucille bank bank bank bank bank bank bank ban...   \n2     hersh premises premises premises agents servan...   \n3     walkway walkway dangerous condition walkway da...   \n4     suffield barbara suffield suffield suffield si...   \n...                                                 ...   \n8212  kuriansky premises premises premises trees tre...   \n8213  parking lot namnoum asylum parking lot parking...   \n8214  norwalk mark norwalk mark norwalk mark norwalk...   \n8215  lindsay lindsay russo ventura ribeiro russo li...   \n8216  gregory marie vehicle gregory vehicle marie ve...   \n\n                                           tfidf_values  \n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n...                                                 ...  \n8212  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n8213  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n8214  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n8215  [0.0308708081311756, 0.041583305384993816, 0.0...  \n8216  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n\n[8217 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:47:34.781474Z","iopub.execute_input":"2024-11-20T02:47:34.781869Z","iopub.status.idle":"2024-11-20T02:47:34.824081Z","shell.execute_reply.started":"2024-11-20T02:47:34.781835Z","shell.execute_reply":"2024-11-20T02:47:34.822815Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\nProcessed Texts with TF-IDF Weights:\n                                                text  \\\n0  I enjoy reading about Machine Learning and Mac...   \n1                   I would enjoy a walk in the park   \n2                       I was reading in the library   \n\n                         processed_text_with_weights  \n0  about(0.257) machine(0.514) learning(0.514) an...  \n1  would(0.460) enjoy(0.349) walk(0.460) in(0.349...  \n2  was(0.517) reading(0.394) in(0.394) the(0.394)...  \n\nDetailed Term Weights for First Document:\nlearning: 0.514\nmachine: 0.514\nabout: 0.257\nand: 0.257\nis: 0.257\nmy: 0.257\nphd: 0.257\nsubject: 0.257\nenjoy: 0.195\nreading: 0.195\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3511231108.py:169: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  weight_value = float(weight)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TFIDF VECTORIZATION complete\n","metadata":{}},{"cell_type":"code","source":"#now we assign numerical values to our \nctemp_df[\"tfidf_values\"] =.values.tolist() \n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:17:17.286791Z","iopub.execute_input":"2024-11-20T02:17:17.287263Z","iopub.status.idle":"2024-11-20T02:17:17.315821Z","shell.execute_reply.started":"2024-11-20T02:17:17.287222Z","shell.execute_reply":"2024-11-20T02:17:17.313961Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#now we assign numerical values to our \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ctemp_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mtolist() \n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'values'","output_type":"error"}]},{"cell_type":"code","source":"print(tfidf_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T02:13:49.606727Z","iopub.execute_input":"2024-11-20T02:13:49.607279Z","iopub.status.idle":"2024-11-20T02:13:49.720202Z","shell.execute_reply.started":"2024-11-20T02:13:49.607227Z","shell.execute_reply":"2024-11-20T02:13:49.718974Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"            aa       aaa  aaaa  aab  aabf  aad  aae  aaf  aag  aai  ...   zs  \\\n0     0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n1     0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n2     0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n3     0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n4     0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n...        ...       ...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...   \n8212  0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n8213  0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n8214  0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n8215  0.030871  0.041583   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n8216  0.000000  0.000000   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n\n       zu  zuboff  zucker  zuckerman  zum  zurich   zy  zygomatic        zz  \n0     0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n1     0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n2     0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n3     0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n4     0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n...   ...     ...     ...        ...  ...     ...  ...        ...       ...  \n8212  0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n8213  0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n8214  0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n8215  0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.045913  \n8216  0.0     0.0     0.0        0.0  0.0     0.0  0.0        0.0  0.000000  \n\n[8217 rows x 23255 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, accuracy_score, auc, confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn import tree\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Embedding, Reshape, Concatenate\n\n\nimport sys\nfrom sklearn.metrics import average_precision_score, accuracy_score, precision_recall_curve, roc_curve, roc_auc_score\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:08:15.624618Z","iopub.execute_input":"2024-11-13T16:08:15.625141Z","iopub.status.idle":"2024-11-13T16:08:15.636592Z","shell.execute_reply.started":"2024-11-13T16:08:15.625098Z","shell.execute_reply":"2024-11-13T16:08:15.634784Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"X = filtered[[\"CaseMajorCode\", \"AttorneySpecialization\", \"CaseLocation\", \"MotionJurisNumber\"]]\ny = filtered[[\"MotionResultCode\"]]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:21:10.174316Z","iopub.execute_input":"2024-11-13T16:21:10.174755Z","iopub.status.idle":"2024-11-13T16:21:10.184186Z","shell.execute_reply.started":"2024-11-13T16:21:10.174713Z","shell.execute_reply":"2024-11-13T16:21:10.182424Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#neural embeddings (first layer of our neural network )","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:21:12.055687Z","iopub.execute_input":"2024-11-13T16:21:12.056557Z","iopub.status.idle":"2024-11-13T16:21:12.061916Z","shell.execute_reply.started":"2024-11-13T16:21:12.056486Z","shell.execute_reply":"2024-11-13T16:21:12.060273Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"TARGET = \"MotionResultCode\" #this is what we are trying to predict\nFEATURES = [col for col in filtered.columns if col != TARGET]\n\ndef neural_embedding(df):\n    X = df.drop(TARGET, axis = 1)\n    y = df[TARGET]\n    \n    #split the training and testing data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n    #combine the x and y set together\n    train = pd.concat([X_train, y_train], axis=1)\n    test = pd.concat([X_test, y_test], axis=1)\n    \n    #creating complete data set\n    X_full = train[FEATURES]\n    y_full = train[TARGET]\n    X_test = test[FEATURES]\n    y_test = test[TARGET]\n    \n    \n    input_models = []\n    embeddings = []\n    for i in FEATURES:\n        embed_name = i.replace(\" \", \"\") + \"__Embedding\"\n        num_unique = X_full[i].nunique()\n        size_embed = int(min(np.ceil((num_unique)/2), 50))\n        \n        #creating input layer for neural network \n        input_mod = Input(shape=(1,), name= f\"{num_unique}_input\")\n        output_mod = Embedding(input_dim=num_unique + 1, output_dim = size_embed, name = embed_name)(input_mod)\n        #reshaps to one dimensional vector\n        output_mod = Reshape(target_shape = (size_embed,))(output_mod)\n        input_models.append(input_mod)\n        embeddings.append(output_mod)\n        \n    final_output = Concatenate()(embeddings) if len(embeddings) > 1 else embeddings[0]\n    model = Model(inputs= input_models, outputs=final_output)\n\n    X_full_list = [X_full[feature].values for feature in FEATURES]\n    X_test_list = [X_test[feature].values for feature in FEATURES]\n\n    X_full_transformed = model.predict(X_full_list)\n    X_test_transformed = model.predict(X_test_list)\n\n    feature_names = [f'feature_{i}' for i in range(X_full_transformed.shape[1])]\n    X_full_df = pd.DataFrame(X_full_transformed, columns=feature_names)\n    X_test_df = pd.DataFrame(X_test_transformed, columns=feature_names)\n\n    return X_full_df, y_full, X_test_df, y_test\n        \n        \n        \n    \n        \n        \n                          \n                        \n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:21:19.758617Z","iopub.execute_input":"2024-11-13T16:21:19.759095Z","iopub.status.idle":"2024-11-13T16:21:19.776195Z","shell.execute_reply.started":"2024-11-13T16:21:19.759052Z","shell.execute_reply":"2024-11-13T16:21:19.774398Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train, y_train, X_test, y_test = neural_embedding(filtered)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:21:23.380019Z","iopub.execute_input":"2024-11-13T16:21:23.381443Z","iopub.status.idle":"2024-11-13T16:21:23.759657Z","shell.execute_reply.started":"2024-11-13T16:21:23.381371Z","shell.execute_reply":"2024-11-13T16:21:23.757697Z"},"trusted":true},"execution_count":66,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mneural_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[65], line 42\u001b[0m, in \u001b[0;36mneural_embedding\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     39\u001b[0m X_full_list \u001b[38;5;241m=\u001b[39m [X_full[feature]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m FEATURES]\n\u001b[1;32m     40\u001b[0m X_test_list \u001b[38;5;241m=\u001b[39m [X_test[feature]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m FEATURES]\n\u001b[0;32m---> 42\u001b[0m X_full_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_full_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_list)\n\u001b[1;32m     45\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_full_transformed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_5_1/MotionJurisNumber__Embedding_1/GatherV2 defined at (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_30/1936890568.py\", line 3, in <module>\n\n  File \"/tmp/ipykernel_30/954127732.py\", line 42, in neural_embedding\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 504, in predict\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 204, in one_step_on_data_distributed\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 194, in one_step_on_data\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 92, in predict_step\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py\", line 146, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4850, in take\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1940, in take\n\nindices[0,0] = 408307 is not in [0, 290)\n\t [[{{node functional_5_1/MotionJurisNumber__Embedding_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_648]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node functional_5_1/MotionJurisNumber__Embedding_1/GatherV2 defined at (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_30/1936890568.py\", line 3, in <module>\n\n  File \"/tmp/ipykernel_30/954127732.py\", line 42, in neural_embedding\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 504, in predict\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 204, in one_step_on_data_distributed\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 194, in one_step_on_data\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 92, in predict_step\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py\", line 146, in call\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4850, in take\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1940, in take\n\nindices[0,0] = 408307 is not in [0, 290)\n\t [[{{node functional_5_1/MotionJurisNumber__Embedding_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_648]","output_type":"error"}]},{"cell_type":"code","source":"pip install GPy","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:24:01.948008Z","iopub.execute_input":"2024-11-13T16:24:01.948481Z","iopub.status.idle":"2024-11-13T16:25:55.875462Z","shell.execute_reply.started":"2024-11-13T16:24:01.948440Z","shell.execute_reply":"2024-11-13T16:25:55.873556Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dcf725e1720>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dcf725e18d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dcf725e1e70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dcf725e2020>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dcf725e21d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m^C\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install Gpy","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:28:25.853119Z","iopub.execute_input":"2024-11-13T16:28:25.853589Z","iopub.status.idle":"2024-11-13T16:30:55.838017Z","shell.execute_reply.started":"2024-11-13T16:28:25.853539Z","shell.execute_reply":"2024-11-13T16:30:55.836337Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79c5e35897e0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79c5e3589990>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79c5e3589d80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79c5e3589f30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79c5e358a0e0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/gpy/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement Gpy (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for Gpy\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#implement the training classifiers\nfrom sklearn import tree\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\n\nimport sys\nfrom sklearn.metrics import average_precision_score, accuracy_score, precision_recall_curve, roc_curve, roc_auc_score\n\nimport numpy as np\n\nimport GPy # efficient Gaussian processes\nfrom scipy.stats import beta\n\ndef evaluate_model(X_test, y_test, model, y_pred=None, pos_class=None):\n    (fpr, tpr, roc_auc), (precision, recall, pr_auc), acc = evaluate(X_test, y_test, model, y_pred, pos_class)\n    return dict(fpr=fpr, tpr=tpr, roc_auc=roc_auc, precision=precision, recall=recall, pr_auc=pr_auc, accuracy=acc)\n\ndef evaluate(X_test, y_test, clf, y_pred=None, pos_class=None):\n    if y_pred is None:\n        if hasattr(clf, 'predict_proba'):\n            y_hat = clf.predict_proba(X_test) # predicting probability for each class\n            pos_class = y_hat[:, 1]\n        else:\n            y_hat = clf.decision_function(X_test) # predicting confidence scores\n            pos_class = y_hat\n        y_pred = clf.predict(X_test)\n\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    fpr, tpr, _ = roc_curve(y_test.ravel(), pos_class)\n    roc_auc = roc_auc_score(y_test, pos_class)\n\n    precision = dict()\n    recall = dict()\n    pr_auc = dict()\n    precision, recall, _ = precision_recall_curve(y_test.ravel(), pos_class)\n    pr_auc = average_precision_score(y_test, pos_class)\n\n    acc = accuracy_score(y_test, y_pred) \n\n    return (fpr, tpr, roc_auc), (precision, recall, pr_auc), acc\n\ndef runDecisionTreeClassifier(x_train,y_train,x_test,y_test):\n    dt = tree.DecisionTreeClassifier()\n\n    parameter_grid = {\n        'criterion': ['gini', 'entropy'],\n        'splitter': ['best', 'random'],\n        'max_depth': [1, 2, 3, 4, 5],\n        'max_features': list(range(1,len(x_train.columns)+1))\n    }\n\n    print(\"Grid search\\n\")\n    grid_search = GridSearchCV(dt, param_grid=parameter_grid, cv=10)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    dt = grid_search.best_estimator_\n    dt_predictions = dt.predict(x_test)\n    dt_score = accuracy_score(y_test, dt_predictions) \n    print(\"decision tree classification accuracy on test data is \" + str(dt_score), file=sys.stderr)\n\n    random_sample = np.random.choice([0,1], len(y_test), replace=True)\n    r_score = accuracy_score(y_test, random_sample) \n    print(\"random algorithm classification accuracy on test data is \" + str(r_score), file=sys.stderr)\n    print(\"feature importances \" + str(dt.feature_importances_), file=sys.stderr)\n    train_score = accuracy_score(y_train, dt.predict(x_train))\n    print(\"accuracy score on training data: \" + str(train_score), file=sys.stderr)\n    \n    return evaluate_model(x_test, y_test, dt)\n\ndef runGradientBoostingClassifier(x_train,y_train,x_test,y_test):\n    gb = GradientBoostingClassifier()\n\n    parameter_grid = {\n        \"loss\":[\"deviance\",\"exponential\"],\n        \"learning_rate\": [0.01, 0.025],\n        \"min_samples_split\": np.linspace(0.1, 0.5, 4),\n        \"min_samples_leaf\": np.linspace(0.1, 0.5, 4),\n        \"max_depth\":[3, 8],\n        \"max_features\":[\"log2\",\"sqrt\",None],\n        \"subsample\":[0.5, 0.618],\n        \"n_estimators\":[10,25,50]\n    }\n    \n    grid_search = GridSearchCV(gb, param_grid=parameter_grid, cv=10)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    gb = grid_search.best_estimator_\n    \n    gb_predictions = gb.predict(x_test)\n    dt_score = accuracy_score(y_test, gb_predictions)\n    print(\"accuracy score on test data: \" +str(dt_score), file=sys.stderr)\n    print(\"feature importances \" + str(gb.feature_importances_), file=sys.stderr)\n    train_score = accuracy_score(y_train, gb.predict(x_train)) \n    print(\"accuracy score on training data: \" + str(train_score), file=sys.stderr)\n    \n    return evaluate_model(x_test, y_test, gb)\n\ndef runAdaBoostClassifier(x_train,y_train,x_test,y_test):\n    ab = AdaBoostClassifier()\n\n    parameter_grid = {\n        \"base_estimator\": [tree.DecisionTreeClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier()],\n        \"learning_rate\": [0.01, 0.025],\n        \"n_estimators\":[10,25,50,100]\n    }\n    \n    grid_search = GridSearchCV(ab, param_grid=parameter_grid, cv=10)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    ab = grid_search.best_estimator_\n    \n    ab_predictions = ab.predict(x_test)\n    dt_score = accuracy_score(y_test, ab_predictions)\n    print(\"accuracy score on test data: \" +str(dt_score), file=sys.stderr)\n    print(\"feature importances \" + str(ab.feature_importances_), file=sys.stderr)\n    train_score = accuracy_score(y_train, ab.predict(x_train)) \n    print(\"accuracy score on training data: \" + str(train_score), file=sys.stderr)\n    \n    return evaluate_model(x_test, y_test, ab)\n\ndef runExtraTreesClassifier(x_train,y_train,x_test,y_test):\n    forest = ExtraTreesClassifier()\n\n    parameter_grid = {\n        \"criterion\": [\"gini\",  \"entropy\"],\n        \"n_estimators\":[10,50,100,250,500],\n        \"max_depth\":[3,5,8,None],\n        \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n        \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n        \"max_features\":[\"log2\",\"sqrt\",None]\n    }\n    \n    grid_search = GridSearchCV(forest, param_grid=parameter_grid, cv=10)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    forest = grid_search.best_estimator_\n    \n    importances = forest.feature_importances_\n    print(importances, file=sys.stderr)\n    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n                 axis=0)\n    indices = np.argsort(importances)[::-1]\n\n    print(\"Feature ranking:\", file=sys.stderr)\n\n    for f in range(x_train.shape[1]):\n        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]), file=sys.stderr)\n\n    etc_predictions = forest.predict(x_test)\n    dt_score =accuracy_score(y_test, etc_predictions)\n    print(\"accuracy score on test data: \" + str(dt_score), file=sys.stderr)\n    train_score = accuracy_score(y_train, forest.predict(x_train))\n    print(\"accuracy score on training data: \" + str( train_score ), file=sys.stderr)\n    return evaluate_model(x_test, y_test, forest)\n\ndef runStochasticGradientDescentClassifier(x_train,y_train,x_test,y_test):\n    sgd = SGDClassifier()\n    \n    parameter_grid = {\n        \"loss\": ['log','modified_huber','squared_hinge'],\n        \"penalty\":['l1', 'l2']\n\n        # \"alpha\":[],\n        # \"fit_intercept\": [],\n        # \"max_iter\":[],\n        # \"tol\": [],\n        # \"shuffle\": [],\n        # \"verbose\": [],\n        # \"epsilon\": [],\n        # \"n_jobs\": [],\n        # \"random_state\": [],\n        # \"eta0\": [],\n        # \"power_t\": [],\n        # \"early_stopping\": [],\n        # \"validation_fraction\": [],\n        # \"n_iter_no_change\": [],\n        # \"class_weight\": [],\n        # \"warm_start\": [],\n        # \"average\": []\n    \n    }\n    \n    grid_search = GridSearchCV(sgd, param_grid=parameter_grid, cv=10)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    sgd = grid_search.best_estimator_\n\n    print(\"Feature ranking:\", file=sys.stderr)\n\n    etc_predictions = sgd.predict(x_test)\n    dt_score =accuracy_score(y_test, etc_predictions)\n    print(\"accuracy score on test data: \" + str(dt_score), file=sys.stderr)\n    train_score = accuracy_score(y_train, sgd.predict(x_train))\n    print(\"accuracy score on training data: \" + str( train_score ), file=sys.stderr)\n    return evaluate_model(x_test, y_test, sgd)\n\ndef runKNeighborsClassifier(x_train,y_train,x_test,y_test):\n    kNC = KNeighborsClassifier()\n\n    parameter_grid = {\n        \"weights\": [\"uniform\",\"distance\"],\n        \"algorithm\":[\"brute\",\"ball_tree\",\"kd_tree\",\"auto\"],\n        #\"n_jobs\":[-1,10,50]\n    }\n    \n    grid_search = GridSearchCV(kNC, param_grid=parameter_grid, cv=5)\n    grid_search.fit(x_train, y_train)\n    print('Best score: {}'.format(grid_search.best_score_), file=sys.stderr)\n    print('Best parameters: {}'.format(grid_search.best_params_), file=sys.stderr)\n\n    kNC = grid_search.best_estimator_\n\n    etc_predictions = kNC.predict(x_test)\n    dt_score =accuracy_score(y_test, etc_predictions)\n    print(\"accuracy score on test data: \" + str(dt_score), file=sys.stderr)\n    train_score = accuracy_score(y_train, kNC.predict(x_train))\n    print(\"accuracy score on training data: \" + str( train_score ), file=sys.stderr)    \n    return evaluate_model(x_test, y_test, kNC)\n\ndef runSparseGaussianProcessClassifier(x_train,y_train,x_test,y_test, num_inducing=10, seed=42, optimize=True, plot=False):\n    x_train = x_train.to_numpy()\n    y_train = y_train.to_numpy()[:,np.newaxis]\n    x_test = x_test.to_numpy()\n    y_test = y_test.to_numpy()[:,np.newaxis]\n    m = GPy.models.SparseGPClassification(x_train, y_train, num_inducing=num_inducing)\n\n    if optimize:\n        m.optimize()\n        \n    if plot:\n        from matplotlib import pyplot as plt\n        fig, axes = plt.subplots(2, 1)\n        m.plot_f(ax=axes[0])\n        m.plot(ax=axes[1])\n\n    print(m)\n    \n    gp_predictions = m.predict(x_test)[0]\n    gp_predictions_soft = m.predict(x_test)[0]\n    print(\"test set predictions: \"+ str(gp_predictions))\n    gp_predictions[gp_predictions>=0.5]=1\n    gp_predictions[gp_predictions<0.5]=0\n    gp_score = accuracy_score(y_test, gp_predictions)\n    print(\"accuracy score on test data: \" +str(gp_score), file=sys.stderr)\n\n    gp_predictions_train = m.predict(x_train)[0]\n    gp_predictions_train[gp_predictions_train>=0.5]=1\n    gp_predictions_train[gp_predictions_train<0.5]=0\n    train_score = accuracy_score(y_train, gp_predictions_train)\n    print(\"accuracy score on training data: \" + str(train_score), file=sys.stderr)\n    return evaluate_model(x_test, y_test, m, gp_predictions, gp_predictions_soft)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T16:22:04.196341Z","iopub.execute_input":"2024-11-13T16:22:04.196798Z","iopub.status.idle":"2024-11-13T16:22:04.408047Z","shell.execute_reply.started":"2024-11-13T16:22:04.196748Z","shell.execute_reply":"2024-11-13T16:22:04.406286Z"},"trusted":true},"execution_count":67,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score, accuracy_score, precision_recall_curve, roc_curve, roc_auc_score\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mGPy\u001b[39;00m \u001b[38;5;66;03m# efficient Gaussian processes\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m beta\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(X_test, y_test, model, y_pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pos_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GPy'"],"ename":"ModuleNotFoundError","evalue":"No module named 'GPy'","output_type":"error"}]}]}